{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ev1025/DA_Study/blob/main/%ED%81%AC%EB%A1%A4%EB%A7%81_%EC%97%B0%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUG4pk9ijzR1"
      },
      "outputs": [],
      "source": [
        "pip install webdriver_manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5V5dRWujzR3"
      },
      "outputs": [],
      "source": [
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKMkgNA-jzR3"
      },
      "outputs": [],
      "source": [
        "pip install BeautifulSoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNsHUU7NjzR4"
      },
      "source": [
        "# 카카오맵 크롤링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSx_q64ZjzR5"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# 크롬 옵션\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('headless')\n",
        "options.add_argument('--disable-gpu--')\n",
        "options.add_argument('lang=ko_KR')\n",
        "\n",
        "# 크롬 드라이버 설치\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
        "\n",
        "# 카카오맵 방문\n",
        "driver.get(\"https://map.kakao.com/\")\n",
        "\n",
        "# 페이지 로드시간 암묵적 대기\n",
        "driver.implicitly_wait(10)\n",
        "\n",
        "# csv 입력받을 DataFrame\n",
        "dog_map_df = pd.DataFrame(columns=('name','star','adr','category'))\n",
        "\n",
        "# 검색 할 목록\n",
        "search_list = ['서울 애견 미용실','서울 애견호텔', '서울 반려동물 미용실',\\\n",
        "                 '서울 동물병원', '서울 강아지 수제간식','서울 애견 수제간식', '서울 애견동반', '서울 강아지유치원','서울 애견유치원', '서울 애견용품']\n",
        "\n",
        "# 목록에서 하나씩 검색\n",
        "for search_id in search_list:\n",
        "    # 검색상자 찾기\n",
        "    search_box = driver.find_element(By.CSS_SELECTOR, \"#search\\.keyword\\.query\")\n",
        "    # 검색할 단어 입력\n",
        "    search_box.send_keys(f\"{search_id}\")\n",
        "    time.sleep(1)\n",
        "    # 검색버튼 누르기\n",
        "    search_box.send_keys(Keys.ENTER)\n",
        "    time.sleep(1)\n",
        "\n",
        "    # 지도설정 팝업 제거(최초 1회만 나타나서 예외구문 적용)\n",
        "    try:\n",
        "        driver.find_element(By.CSS_SELECTOR, \"body > div.coach_layer.coach_layer_type1 > div > div > div > span\").click()\n",
        "    except:\n",
        "        pass\n",
        "    time.sleep(1)\n",
        "\n",
        "    # 최초에 페이지번호 뜨지 않고 더보기 눌러줘야함(최초 1회만 나타나서 예외구문 적용)\n",
        "    try:\n",
        "        more_btn = driver.find_element(By.CSS_SELECTOR, \"#info\\.search\\.place\\.more\")\n",
        "        more_btn.click()\n",
        "    except:\n",
        "        pass\n",
        "    time.sleep(1)\n",
        "\n",
        "    # dog_map_df에 입력받을 컬럼\n",
        "    name = []\n",
        "    star = []\n",
        "    adr = []\n",
        "    category = []         \n",
        "    \n",
        "    # 크롤링 시작\n",
        "    # 페이지당 15개의 개체가 있다.\n",
        "    # 이전, 페이지 1~5, 다음 버튼이 존재하며, 이전,다음버튼은 5개씩 넘어가게 되어있음\n",
        "    \n",
        "    # 다음버튼 누르는 횟수 개체 개수 = (15개 x 5page x 다음버튼 횟수)\n",
        "    for p in range(16):\n",
        "        # 1page ~ 5page 페이지이동 (6~10, 11~15 ...)\n",
        "        # page버튼이 모자르면 종료(6~10구간에서 6,7,8까지만 있으면 8page에서 종료)\n",
        "        for j in range(1,6):\n",
        "            try:\n",
        "                next_btn_1stp = driver.find_element(By.CSS_SELECTOR, f\"#info\\.search\\.page\\.no{j}\")\n",
        "                next_btn_1stp.click()\n",
        "            except:\n",
        "                break\n",
        "            time.sleep(1)\n",
        "\n",
        "            # 추출할 범위를 CSS로 선택해서 HTML형식으로 변환\n",
        "            js_script = \"document.querySelector('.placelist').innerHTML\"\n",
        "            # 자바스크립트형식 읽어들이기\n",
        "            raw = driver.execute_script(\"return \" + js_script)\n",
        "            html = BeautifulSoup(raw, 'html.parser')\n",
        "            time.sleep(2)\n",
        "\n",
        "            # 직접적인 데이터가 있는 CSS그룹 선택하여 HTML형식을 list에 저장\n",
        "            contents = html.find_all(class_='PlaceItem clickArea')\n",
        "            time.sleep(2)\n",
        "\n",
        "            # CSS그룹에서 필요한 값 추출\n",
        "            for i in contents:\n",
        "                cr_name = i.find(class_='link_name').text\n",
        "                name.append(cr_name)\n",
        "\n",
        "                try:\n",
        "                    cr_star = float(i.select_one(\"em.num\").text)\n",
        "                    star.append(cr_star)\n",
        "                except:\n",
        "                    star.append(0)\n",
        "\n",
        "                cr_adr = i.select_one('.addr').text.replace('\\n', '').split(' ')\n",
        "                if cr_adr[0] == '서울':\n",
        "                    adr.append(cr_adr[1])\n",
        "\n",
        "                cr_category = i.find(class_='subcategory clickable').text\n",
        "                category.append(cr_category)\n",
        "                \n",
        "\n",
        "        try:\n",
        "            next_btn = driver.find_element(By.XPATH,'//*[@id=\"info.search.page.next\"]')\n",
        "            next_btn.send_keys(Keys.ENTER)\n",
        "        except:\n",
        "            print(f'{search_id}수집 끝')\n",
        "            break\n",
        "\n",
        "   \n",
        "    # 추출한 데이터 입력\n",
        "    search_data = pd.DataFrame({'name':name,'star':star,'adr':adr,'category':category})\n",
        "    dog_map_df = pd.concat([dog_map_df,search_data]) \n",
        "  \n",
        "    # 검색어 지우기\n",
        "    driver.implicitly_wait(3)\n",
        "    search_box.clear()\n",
        "    \n",
        "\n",
        "# 중복제거\n",
        "dog_map_df.drop_duplicates(['name'], keep='first', inplace=True)\n",
        "\n",
        "# csv파일로 저장\n",
        "dog_map_df.to_csv(path_or_buf=f'./dog_map_data.csv',encoding='utf-8-sig', index=False)\n",
        "\n",
        "# 크롬 웹페이지를 닫음\n",
        "driver.close()\n",
        "\n",
        "dog_map_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qeTCtcSjzR7"
      },
      "source": [
        "### 탑텐몰 제품, 가격, 할인률"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn6l8TLPjzR8"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "driver = webdriver.Chrome(\"C:/Users/eg287/chromedriver\") # 나의 웹드라이버의 위치(설정-도움말-버전에서 확인 후 최신 드라이버 사용)\n",
        "driver.get(\"https://www.topten10mall.com/kr/front/search/categorySearch.do?ctgNo=37341\") # 웹사이트 방문\n",
        "\n",
        "# 팝업 창 제거\n",
        "# driver.find_element(By.CSS_SELECTOR, \"button#intro_popup_close\").click()\n",
        "driver.implicitly_wait(10) # 페이지 로드시간에 10초 암묵적 대기\n",
        "\n",
        "# 검색창에 검색어 입력하기\n",
        "search_box = driver.find_element(By.CSS_SELECTOR, \"#searchWord\")\n",
        "search_box.send_keys(\"맨투맨\")\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "# 검색버튼 누르기\n",
        "search_box.send_keys(Keys.ENTER)\n",
        "# raw = driver.page_source # 현재 랜더링된 페이지의 정보를 가져옴\n",
        "\n",
        "# 추출한 데이터 저장할 DataFrame 생성\n",
        "empty = pd.DataFrame(columns=['name','price','discount'])\n",
        "num = 0 # 추출한 값을 넣을 인덱스번호\n",
        "\n",
        "# 크롤링\n",
        "for p in range(28):\n",
        "    # 5초 delay\n",
        "    time.sleep(2)\n",
        "    \n",
        "    # 자바로 HTML가져오기(추출할 범위)\n",
        "    js_script = \"document.querySelector('#divList').innerHTML\"\n",
        "    raw = driver.execute_script(\"return \" + js_script)\n",
        "    \n",
        "    # requests로 HTML 가져오기\n",
        "    # raw = requests.get(\"https://www.topten10mall.com/kr/front/search/totalSearch.do?searchTerm=%EC%85%94%EC%B8%A0\")\n",
        "\n",
        "    # 파서로 추출할 대상 선택\n",
        "    html = BeautifulSoup(raw, 'html.parser')\n",
        "    contents = html.select('.card-goods__body')\n",
        "\n",
        "    # 추출대상별 구체적으로 추출할 클래스 값 추출\n",
        "    for i in contents:\n",
        "        name = i.select_one('.card-goods__text').text\n",
        "        try:\n",
        "            price = i.select_one('.card-goods__price').text\n",
        "        except:\n",
        "            price = 'NULL'\n",
        "        try:\n",
        "            discount = i.select_one('.card-goods__discount').text\n",
        "        except:\n",
        "            discount = '0%'\n",
        "\n",
        "        # empty 데이터프레임에 추출한 값 넣기\n",
        "        empty_dict = {'name':name, 'price':price, 'discount':discount}\n",
        "        for key,value in empty_dict.items():\n",
        "            empty.loc[num,key] = value\n",
        "        num += 1 # 인덱스 번호 1씩 증가하도록\n",
        "        # print(name, price, discount)\n",
        "        \n",
        "        \n",
        "    # 다음 페이지로 이동(다음페이지 없을때까지)\n",
        "    try:\n",
        "        next_btn = driver.find_element(By.CSS_SELECTOR, '#searchGoods > nav > ul > li:nth-last-child(1)')\n",
        "        next_btn.click()\n",
        "    except:\n",
        "        print(\"데이터 수집 완료\")\n",
        "        break\n",
        "\n",
        "\n",
        "# empty.to_csv(path_or_buf='./크롤링.csv',index=False, encoding = \"utf-8-sig\")\n",
        "len(empty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP4M_FCmjzR9"
      },
      "source": [
        "### 네이버 실패"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56A6cqdvjzR9"
      },
      "outputs": [],
      "source": [
        "# 네이버 안돼\n",
        "url = 'https://map.naver.com/v5/favorite/myPlace/folder/74b5e2268e0444c999227a4ec63e2839?c=10.53,0,0,0,dh'\n",
        "html = requests.get(url)\n",
        "soup = BeautifulSoup(html.content,'html.parser')\n",
        "soup\n",
        "# data = soup.select('.\\_2gfp\\-T')\n",
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxA8G-VkjzR-"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "driver = webdriver.Chrome(\"C:/Users/eg287/chromedriver\") # 나의 웹드라이버의 위치(설정-도움말-버전에서 확인 후 최신 드라이버 사용)\n",
        "driver.get(\"https://map.naver.com/v5/?c=15,0,0,0,dh\")            # 웹사이트 방문\n",
        "\n",
        "\n",
        "# 팝업 창 제거\n",
        "# driver.find_element(By.CSS_SELECTOR, \"button#intro_popup_close\").click()\n",
        "driver.implicitly_wait(10) # 페이지 로드시간에 10초 암묵적 대기\n",
        "\n",
        "search_list = ['서울 동물병원']\n",
        "# ,'서울 반려동물 미용실', '서울 강아지 간식', '서울 애견동반', '서울 강아지호텔', '서울 강아지유치원'\n",
        "for search_id in search_list:\n",
        "\n",
        "    # 검색창에 검색어 입력하기\n",
        "    search_box = driver.find_element(By.CSS_SELECTOR, \"div.input_box>input.input_search\")\n",
        "    search_box.send_keys(f\"{search_id}\")\n",
        "\n",
        "    time.sleep(3)\n",
        "\n",
        "    # 검색버튼 누르기\n",
        "    search_box.send_keys(Keys.ENTER)\n",
        "\n",
        "    name = []\n",
        "    adr = []\n",
        "    category = []\n",
        "\n",
        "\n",
        "    # 크롤링\n",
        "    for p in range(1):\n",
        "            #5초 delay\n",
        "            time.sleep(2)\n",
        "            \n",
        "            js_script = \"document.querySelector('*').innerHTML\"\n",
        "            raw = driver.execute_script(\"return \" + js_script)\n",
        "            html = BeautifulSoup(raw, 'html.parser')\n",
        "            \n",
        "            contents = html.find_all(class_='VLTHu OW9LQ')\n",
        "\n",
        "            for i in contents:\n",
        "                name.append(i.select_one(\" span.place_bluelink YwYLL\").text)\n",
        "\n",
        "                address = i.select_one('#_pcmap_list_scroll_container > ul > li:nth-child(1) > div.qbGlu > div.ouxiq.icT4K > div > div > span > a > span.hClKF').text.replace('\\n', '').split(' ')\n",
        "                if address[0] =='서울':\n",
        "                    adr.append(address[1])\n",
        "                \n",
        "                category.append(i.select_one('#_pcmap_list_scroll_container > ul > li:nth-child(1) > div.qbGlu > div.ouxiq.icT4K > a:nth-child(1) > div > div > span.YzBgS').text)\n",
        "            \n",
        "            try:    \n",
        "                next_btn = driver.find_element(By.CSS_SELECTOR, \"#app-root > div > div.XUrfU > div.zRM9F > a:nth-child(7) > svg\")\n",
        "                next_btn.click()\n",
        "            except:\n",
        "                print(\"데이터 수집 완료\")\n",
        "                break\n",
        "        \n",
        "    \n",
        "    search_data = pd.DataFrame({'name':name,'adr':adr,'category':category})        \n",
        "    search_data.to_csv(path_or_buf=f'./{search_id}.csv',encoding='utf-8-sig', index=False)\n",
        "    \n",
        "    # 검색어 지우기\n",
        "    search_box.clear()\n",
        "\n",
        "\n",
        "\n",
        "# 크롬 웹페이지를 닫음\n",
        "# driver.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}